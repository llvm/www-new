talks:
- title: "Towards OpenMP Support in LLVM"
  speaker: "Andrey Bokhanko & Alexey Bataev (Intel)"
  slides_url: "https://llvm.org/devmtg/2013-04/bokhanko-bataev-slides.pdf"
  video_url: "https://youtu.be/9SkYb8YWRA8"
  description: "In this talk, we present our efforts and plans for OpenMP support in the LLVM compiler infrastructure."

- title: "Dagger: decompilation to LLVM IR"
  speaker: "Ahmed Bougacha"
  slides_url: "https://llvm.org/devmtg/2013-04/bougacha-slides.pdf"
  video_url: "https://youtu.be/JoOC3vqnh-s"
  description: "Dagger is a decompilation framework based on LLVM. It enables existing backends to easily provide instruction-level semantics. These are then used to translate target instructions to an IR-like architecture, Mir (for micro-IR), and further to LLVM IR itself. Dagger also enables easy retargetability of several planned tools, like rewriters, static or dynamic binary translators (with valgrind-like instrumentation), and even simple instruction set emulators. The IR can also be transformed to do static analysis, or even, using a revived and improved C backend, full-blown decompilation."

- title: "Debug Info - Status and Directions"
  speaker: "Eric Christopher (Google)"
  slides_url: "https://llvm.org/devmtg/2013-04/christopher-slides.pdf"
  video_url: "https://youtu.be/EpFel-1mpK0"
  description: "In the last few years, Clang and LLVM have made great inroads as the default compilers in the open source world and in industry. It is now seeing daily use as the default compiler for all of the Apple ecosystem, FreeBSD, and as one of the compilers at Google. As a compiler matures and its user base expands the quality of the debug information output becomes more important. In the past users of clang and LLVM have had to deal with poor debug information, but in the last couple years the quality of debug information has improved greatly and in some cases we are pushing the boundaries of existing standards. We've made good progress with gdb testing and implementing DWARF4 including the extensions for C++11. Furthermore, we've implemented and are proposing for inclusion in DWARF5 support for split debug information and faster access to named debug entities."

- title: "clang-format - Automatic formatting for C++"
  speaker: "Daniel Jasper (Google)"
  slides_url: "https://llvm.org/devmtg/2013-04/jasper-slides.pdf"
  video_url: "https://youtu.be/5eplO4qpxCY"
  description: "Source code readability is an important aspect to ensure quality and long-term maintainability. However, manually formatting is a tedious job that simply takes a chunk out of every programmer's productivity. Moreover, the tediousness can actively discourage refactorings, e.g. removing or restructuring a function's parameters. There are tools that can provide some level of intelligent auto-formatting, but no tool has so far been able to keep developers happy in a reasonably-sized codebase. Therefore, we have set out to build clang-format, an intelligent C++ formatter based on Clang's infrastructure."

- title: "Performing Source-to-Source Transformations with Clang"
  speaker: "Olaf Krzikalla (TU Dresden)"
  slides_url: "https://llvm.org/devmtg/2013-04/krzikalla-slides.pdf"
  video_url: "https://youtu.be/IKDROD29Sz4"
  description: "Back in 2009, we started to develop a configurable source-to-source transformation tool designed to automatically vectorize C/C++ source code using SIMD instructions. Meanwhile the tool, called Scout, is an industrial-strength vectorizing preprocessor, which is used on a day-to-day basis in the software production process of the German Aerospace Center. The code is published as Open Source and can be downloaded from http://scout.zih.tu-dresden.de. The source-to-source transformation framework of Scout is based on the AST and the accompanying infrastructure of Clang. Beside the actual vectorization the framework provides function inlining, loop-unrolling and loop-unswitching at AST level. For this a C/C++ file is parsed, the generated AST is transformed and then written back to a target file. However this approach is critical, since the AST of Clang is actually immutable by design. On the other hand there is a lot of interest in source-to-source transformation tools based on Clang, as can be seen on cfe-dev and in other talks. In our talk we will present our experiences, the technologies used and possible future directions of the development of source-to-source transformation tools."

- title: "LLVM Interpreter, a key component in validation of OpenCL compilers"
  speaker: "Oleg Maslov (Intel)"
  slides_url: "https://llvm.org/devmtg/2013-04/maslov-slides.pdf"
  video_url: "https://youtu.be/XPi-74rHo9U"
  description: "In this presentation we show how we use LLVM interpreter to create a validation tool chain for OpenCL compilers which is isolated from the OpenCL runtime. LLVM interpreter produces bitwise accurate results and is used as a reference OpenCL engine. This infrastructure is used in pre silicon enablement of MIC and X86 OpenCL compilers. It is also used to validate correctness of the workloads during ongoing development of the compilers. As part of the work we extended existing interpreter to support the missing vector and aggregate data types and plan to upstream the changes to llvm.org."

- title: "An experimental framework for Pragma Handling in Clang"
  speaker: "Simone Pellegrini (University of Innsbruck)"
  slides_url: "https://llvm.org/devmtg/2013-04/pellegrini-slides.pdf"
  video_url: "https://youtu.be/wH4bP0p9qdc"
  description: "Clang is one of the fully featured C/C++ frontend which managed to bring compiler research into the mainstream. Its clean interfaces and structure enabled several new research ideas to be applied to real codes in a scale that was never possible in the past. However, one of the main sin of researchers is the need to extend the language. Since C allows language extensions through the #pragma preprocessor directive, many have used this medium for feeding meta-information to the compiler analysis module. A very famous example is the OpenMP standard. This is an extension to the semantics of C/C++ which grants to the compiler the possibility of parallelizing a portion of the input code. However Clang's support for pragmas is lacking and primitive at most. Clang allows pragma handlers to be registered for a particular pragma but the user is left with the burden of parsing the tokens returned by the lexer. This is not a problem for many extensions which rely on simple keywords and integer identifiers, however it can become a parsing nightmare if a C expression is allowed in the pragma (as it is the case for OpenMP). In those cases, the user has to provide its own expression parser which basically means rewriting Clang's parser. My solution relies on a simple idea, i.e. exposing the full Clang parser to pragma handlers. Together with a framework which allows pragma definition to be specified in EBNF form, new language extensions can be easily defined in a single line of C++ code."

- title: "lld - Solving the Linking Performance Problem"
  speaker: "Michael Spencer (Sony)"
  slides_url: "https://llvm.org/devmtg/2013-04/spencer-slides.pdf"
  video_url: "https://youtu.be/ONGVraXbJOo"
  description: "lld is a LLVM subproject with the goal of building a fast, modular, and cross platform linker. lld is under very active development. It can currently link moderately complex programs, including itself and LLVM. Link time performance is a critical part of lld, and it takes several measures to improve it. The Atom graph model simplifies linking which also makes parallelizing the link simpler. It also provides a method to evaluate linker scripts without serializing the entire link. We have also taken a step back to look at the entire linking process and have found a major area for improvement. A significant amount of time while linking is spent reading object files and converting the information they contain into a format suitable for the linker. We can improve this by reading in parallel and reading lazily, however this can only take us so far. The real solution is to have the compiler emit object files designed for linking performance. Since we have a simple internal model in the linker, we have developed a native object file format that matches this model and that is designed specifically for linking performance. It is designed around the data structures and algorithms used in linking, while still maintaining all of the semantics of various object file formats. It is also very easy for compilers to generate. This allows us to bypass the work of processing traditional object files and jump directly to the core linking process. This talk will explore the the linking performance problem and lld's solutions."

- title: "Run-time tracking of uninitialized data with MemorySanitizer"
  speaker: "Evgeniy Stepanov (Google)"
  slides_url: "https://llvm.org/devmtg/2013-04/stepanov-slides.pdf"
  video_url: "https://youtu.be/2Y0T-1AB-gY"
  description: "MemorySanitizer is a detector of uninitialized reads, inspired by Valgrind/Memcheck and DrMemory, but based on compiler instrumentation technology. It was mentioned in the 2012 LLVM DevMtg; since then MemorySanitizer (MSan) has grown and improved and has been accepted in LLVM 3.3 trunk. It is now able to bootstrap Clang with a 3.7x slowdown and has detected multiple bugs in LLVM, Chromium, etc. Unlike AddressSanitizer and ThreadSanitizer, MSan has a very simple run-time library and a complex instrumentation module. Another difference is the need for full program instrumentation. We provide a helper tool based on DynamoRio instrumentation framework to deal with this. This talk will concentrate on MSan internals and implementation issues."

- title: "LLVM on IBM POWER processors: a progress report"
  speaker: "Ulrich Weigand (IBM)"
  slides_url: "https://llvm.org/devmtg/2013-04/weigand-slides.pdf"
  video_url: "https://youtu.be/eSIk4FPH7O0"
  description: "Until recently, use of LLVM on IBM processors, in particular POWER, was not an issue of particular interest to IBM, and we were not directly involved in LLVM development. This situation changed significantly during the past year, as a result of more widespread use of LLVM, in particular its just-in-time compiler, as an essential component of widely used open-source and proprietary applications, and increased customer requests for LLVM capabilities on IBM platforms. This led to the decision to get actively involved with the LLVM community, and form a team within the IBM Linux Technology Center to help enable full support for LLVM on PowerLinux. Over the past several months, we have made significant progress towards that goal; in particular, the LLVM 3.2 release now bootstraps and passes all test suites on PowerLinux, and provides a working (MC) JIT implementation. In this presentation I plan to report on IBM's involvement with LLVM as described above and the work we've done so far, including various missing features that were contributed, like support for the JIT, the assembler parser and disassembler, full TLS support, medium and large code models, full ABI compatibility, and Altivec enhancements. I will also present methods we used to verify correctness of the port, and show some examples of the more interesting bugs we found and fixed in the process. As a long-time GCC developer with no prior experience with LLVM, I will also try to give some impressions on my 'learning curve' with the LLVM design and code base, in particular from the perspective of a processor back-end: which parts were easy to get into, and what took significant effort getting used to. Finally, I will conclude by presenting ongoing work on features that are still missing to provide first-class support for POWER, and our plans for future continued involvement with LLVM."
